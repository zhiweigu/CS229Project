{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMA: A Dataset For Music Analysis\n",
    "\n",
    "MichaÃ«l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "* This notebook evalutates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on both audio and spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/dtgo/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/dtgo/anaconda3/lib/python3.6/site-packages/dotenv/main.py:24: UserWarning: Not loading  - it doesn't exist.\n",
      "  warnings.warn(\"Not loading %s - it doesn't exist.\" % dotenv_path)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13129, 249)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "tracks = utils.load('data/tracks.csv')\n",
    "features = utils.load('data/features.csv')\n",
    "echonest = utils.load('data/echonest.csv')\n",
    "print(echonest.shape)\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (35): [' ', '-', '/', 'B', 'C', 'E', 'F', 'H', 'I', 'J', 'L', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'g', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'x', 'y', 'z']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multiple classifiers and feature sets\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = enc.fit_transform(labels[train])\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    X_train = features.loc[train, columns].as_matrix()\n",
    "    X_val = features.loc[val, columns].as_matrix()\n",
    "    X_test = features.loc[test, columns].as_matrix()\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### softmax regression ########\n",
    "## loss function of softmax regression\n",
    "def getLoss(w,x,y,lam):\n",
    "    m = x.shape[0] #number of training example\n",
    "    y_mat = oneHotIt(y)  #convert the interger class coding in to a one-hot representation\n",
    "    scores = np.dot(x,w) #comput raw class scores given input and current weight\n",
    "    prob = softmax(scores) #perform softmax on these scores to get their probabilities\n",
    "    loss = (-1 / m) * np.sum(y_mat * np.log(prob)) + (lam/2)*np.sum(w*w) #We then find the loss of the probabilities\n",
    "    grad = (-1 / m) * np.dot(x.T, (y_mat - prob)) + lam*w #And compute the gradient for the loss\n",
    "    \n",
    "    return loss, grad\n",
    "\n",
    "## unidimentional array of labels into a one-hot varient\n",
    "def oneHotIt(Y):\n",
    "    m = Y.shape[0]\n",
    "    OHX = scipy.sparse.csr_matrix((np.ones(m),(Y,np.array(range(m)))))\n",
    "    OHX = np.array(OHX.todense()).T\n",
    "    return OHX\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    sm = (np.exp(z).T / np.sum(np.exp(z),axis=1)).T\n",
    "    return sm\n",
    "\n",
    "## determine the probabilities and predictions for each class when given a set of input data:\n",
    "def getProbsAndPreds(someX,w):\n",
    "    probs = softmax(np.dot(someX,w))\n",
    "    preds = np.argmax(probs,axis=1)\n",
    "    return probs, preds\n",
    "\n",
    "##\n",
    "def getAccuracy(someX,someY,w):\n",
    "    prob, prede = getProbsAndPreds(someX,w)\n",
    "    accuracy = sum(prede == someY)/(float(len(someY)))\n",
    "    return accuracy\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "\n",
    "    \n",
    "    columns = ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "             'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "             'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "    \n",
    "    y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features, columns, multi_label=False, verbose=False);\n",
    "\n",
    "\n",
    "    \n",
    "    M = X_train.shape[0]/10\n",
    "    X_learning = np.empty(10)\n",
    "    Y_train_curve = np.empty(10)\n",
    "    Y_test_curve = np.empty(10)\n",
    "    for j in range(10):\n",
    "        MJ = int(M*j)\n",
    "        X_train_this = np.delete(X_train,np.s_[0:MJ],axis=0)\n",
    "        Y_train_this = np.delete(y_train,np.s_[0:MJ],axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "        w = np.zeros([X_train_this.shape[1], 16])   #len(np.unique(Y_train_this)=16\n",
    "        lam = 1\n",
    "        iterations = 5000\n",
    "        learningRate = 1e-4\n",
    "        losses = []\n",
    "               \n",
    "        for i in range(0,iterations):\n",
    "            loss, grad = getLoss(w,X_train_this,Y_train_this,lam)\n",
    "            losses.append(loss)\n",
    "            w = w - (learningRate * grad)\n",
    "        \n",
    "        X_learning[j] = (10-j)*M\n",
    "        Y_train_curve[j] = getAccuracy(X_train_this,Y_train_this,w)\n",
    "        Y_test_curve[j] = getAccuracy(X_val,y_val,w)\n",
    "        print('Training Accuracy:', Y_train_curve[j])\n",
    "        print('Test Accuracy:', Y_test_curve[j])\n",
    "      \n",
    "    plt.plot(X_learning, Y_train_curve, linewidth = 2.0, color = 'red')\n",
    "    plt.plot(X_learning, Y_test_curve, linewidth = 2.0, color = 'blue')\n",
    "    plt.show()\n",
    "    #print('Training Accuracy:', getAccuracy(X_train,y_train,w))\n",
    "    #print('Test Accuracy:', getAccuracy(X_test,y_test,w))\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])\n",
    "classifiers = {\n",
    "}\n",
    "feature_sets = {\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "test_classifiers_features(classifiers, feature_sets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape:  (19922, 518) (19922,)\n",
    "2.72712255201\n",
    "Training Accuracy: 0.479670715792\n",
    "Test Accuracy: 0.47260007773\n",
    "shape:  (17930, 518) (17930,)\n",
    "2.72705942451\n",
    "Training Accuracy: 0.482208588957\n",
    "Test Accuracy: 0.471822774971\n",
    "shape:  (15938, 518) (15938,)\n",
    "2.72656854697\n",
    "Training Accuracy: 0.482933868741\n",
    "Test Accuracy: 0.472211426351\n",
    "shape:  (13946, 518) (13946,)\n",
    "2.72629859806\n",
    "Training Accuracy: 0.485730675462\n",
    "Test Accuracy: 0.474154683249\n",
    "shape:  (11954, 518) (11954,)\n",
    "2.72631561022\n",
    "Training Accuracy: 0.487870168981\n",
    "Test Accuracy: 0.474931986009\n",
    "shape:  (9961, 518) (9961,)\n",
    "2.72590218012\n",
    "Training Accuracy: 0.492219656661\n",
    "Test Accuracy: 0.475709288768\n",
    "shape:  (7969, 518) (7969,)\n",
    "2.72544865504\n",
    "Training Accuracy: 0.492784540093\n",
    "Test Accuracy: 0.471822774971\n",
    "shape:  (5977, 518) (5977,)\n",
    "2.72425531267\n",
    "Training Accuracy: 0.497574033796\n",
    "Test Accuracy: 0.474543334629\n",
    "shape:  (3985, 518) (3985,)\n",
    "2.72301800337\n",
    "Training Accuracy: 0.502885821832\n",
    "Test Accuracy: 0.474931986009\n",
    "shape:  (1993, 518) (1993,)\n",
    "2.72654753076\n",
    "Training Accuracy: 0.508278976417\n",
    "Test Accuracy: 0.482316362223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()).insert(0, 'dim') # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores_test = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    scores_train = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        \n",
    "        # Guzhiwei ********\n",
    "        model = SelectKBest(k=200)\n",
    "        fit = model.fit(X_train, y_train)\n",
    "        X_train = fit.transform(X_train)\n",
    "        X_test = fit.transform(X_test)\n",
    "        \n",
    "        # Guzhiwei *********\n",
    "        \n",
    "        scores_test.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        scores_train.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            # train the model;\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # for training data\n",
    "            Y_predict_train = clf.predict(X_train)\n",
    "            Precision_recall_train = precision_recall_fscore_support(y_train, Y_predict_train)\n",
    "            score_train = clf.score(X_train, y_train) # accuracy for function clf.\n",
    "            scores_train.loc[fset_name, clf_name] = score_train\n",
    "            confusion_train = confusion_matrix(y_train, Y_predict_train, labels=labels) #, sample_weight=Precision_recall_train[3])\n",
    "            \n",
    "            # for test data\n",
    "            Y_predict_test = clf.predict(X_test)\n",
    "            Precision_recall_test = precision_recall_fscore_support(y_test, Y_predict_test)\n",
    "            score_test = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            scores_test.loc[fset_name, clf_name] = score_test\n",
    "            confusion_test = confusion_matrix(y_test, Y_predict_test, labels=labels) #, sample_weight=Precision_recall_test[3])\n",
    "            \n",
    "            # for time\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores_test, scores_train, times, Precision_recall_train, Precision_recall_test, confusion_train, confusion_test\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])\n",
    "\n",
    "classifiers = {\n",
    "     'SVC'\n",
    "}\n",
    "\n",
    "# feature_sets = features.columns.levels[0];\n",
    "feature_sets = {\n",
    "     'all': ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "           'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "           'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "}\n",
    "\n",
    "\n",
    "# test_classifiers_features:\n",
    "# scores.test, scores.train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "scores_test, scores_train, times, Precision_recall_train, Precision_recall_test, confusion_train, confusion_test = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores_test))\n",
    "ipd.display(format_scores(scores_train))\n",
    "#ipd.display(format_scores(score))\n",
    "ipd.display(times.style.format('{:.4f}'))\n",
    "ipd.display(Precision_recall_train)\n",
    "ipd.display(Precision_recall_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
