{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa # for audio and music analysis\n",
    "import librosa.display\n",
    "import csv\n",
    "import math\n",
    "import datatables\n",
    "import ast\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((163, 4), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory where mp3 are stored.\n",
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "# Load metadata and features.\n",
    "tracks = utils.load('tracks.csv')\n",
    "genres = utils.load('genres.csv')\n",
    "features = utils.load('features.csv')\n",
    "echonest = utils.load('echonest.csv')\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, \n",
    "genres.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959555803474\n",
      "19922 training examples, 2573 testing examples\n",
      "230 features, 16 classes\n"
     ]
    }
   ],
   "source": [
    "medium = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "X_train = features.loc[medium & train,:]\n",
    "X_test = features.loc[medium & test,:]\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "#transform to PC space\n",
    "estimator = PCA(n_components = 230)\n",
    "X_train = estimator.fit_transform(X_train)\n",
    "variance_explained = estimator.explained_variance_ratio_\n",
    "print(np.sum(variance_explained))\n",
    "X_test = estimator.transform(X_test)\n",
    "\n",
    "print('{} training examples, {} testing examples'.format(y_train.size, y_test.size))\n",
    "print('{} features, {} classes'.format(X_train.shape[1], np.unique(y_train).size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.66%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=141, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "print('Accuracy: {:.2%}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518 features, 16 classes\n",
      "Accuracy: 44.58%\n",
      "518 features, 16 classes\n",
      "Accuracy: 44.58%\n",
      "518 features, 16 classes\n",
      "Accuracy: 49.01%\n",
      "518 features, 16 classes\n",
      "Accuracy: 50.52%\n",
      "518 features, 16 classes\n",
      "Accuracy: 51.57%\n",
      "518 features, 16 classes\n",
      "Accuracy: 51.85%\n",
      "518 features, 16 classes\n",
      "Accuracy: 52.20%\n",
      "518 features, 16 classes\n",
      "Accuracy: 52.62%\n",
      "518 features, 16 classes\n",
      "Accuracy: 52.82%\n"
     ]
    }
   ],
   "source": [
    "#searching optimal k without PCA transformation\n",
    "accuracy = []\n",
    "for i in range(1, 10):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    \n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "    print('{} features, {} classes'.format(X_train.shape[1], np.unique(y_train).size))\n",
    "    \n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(score))\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.11%\n",
      "Accuracy: 55.77%\n",
      "Accuracy: 54.99%\n",
      "Accuracy: 55.23%\n",
      "Accuracy: 55.23%\n",
      "Accuracy: 55.15%\n",
      "Accuracy: 54.99%\n",
      "Accuracy: 55.15%\n",
      "Accuracy: 54.72%\n",
      "Accuracy: 55.46%\n",
      "Accuracy: 55.27%\n",
      "Accuracy: 55.15%\n",
      "Accuracy: 55.54%\n",
      "Accuracy: 55.27%\n",
      "Accuracy: 55.15%\n",
      "Accuracy: 55.34%\n",
      "Accuracy: 55.54%\n",
      "Accuracy: 55.58%\n",
      "Accuracy: 55.38%\n",
      "Accuracy: 55.23%\n"
     ]
    }
   ],
   "source": [
    "#searching optimal number of PC with k=20\n",
    "accuracy = []\n",
    "for i in range(125, 145):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "\n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "    #transform to PC space\n",
    "    estimator = PCA(n_components = i)\n",
    "    X_train = estimator.fit_transform(X_train)\n",
    "    #variance_explained = estimator.explained_variance_ratio_\n",
    "    #print('{:.2%} variance explained'.format(np.sum(variance_explained)))\n",
    "    X_test = estimator.transform(X_test)\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    accuracy = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.98%\n"
     ]
    }
   ],
   "source": [
    "#search for optimal k with 200 selected feature \n",
    "medium = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "X_train = features.loc[medium & train,:]\n",
    "X_test = features.loc[medium & test,:]\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "model = SelectKBest(k=169)\n",
    "fit = model.fit(X_train, y_train)\n",
    "X_train = fit.transform(X_train)\n",
    "X_test = fit.transform(X_test)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_train, y_train)\n",
    "print('Accuracy: {:.2%}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.75%\n",
      "Accuracy: 57.75%\n",
      "Accuracy: 57.60%\n",
      "Accuracy: 57.29%\n",
      "Accuracy: 57.83%\n",
      "Accuracy: 57.68%\n",
      "Accuracy: 57.36%\n",
      "Accuracy: 57.25%\n",
      "Accuracy: 57.21%\n",
      "Accuracy: 57.87%\n"
     ]
    }
   ],
   "source": [
    "#search for optimal feature size with k = 20\n",
    "medium = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "#searching optimal k without PCA transformation\n",
    "for i in range(160, 170):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "\n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    model = SelectKBest(k=i)\n",
    "    fit = model.fit(X_train, y_train)\n",
    "    X_train = fit.transform(X_train)\n",
    "    X_test = fit.transform(X_test)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.28% variance explained\n",
      "Accuracy: 50.87%\n",
      "96.80% variance explained\n",
      "Accuracy: 50.87%\n",
      "98.31% variance explained\n",
      "Accuracy: 50.87%\n",
      "99.21% variance explained\n",
      "Accuracy: 50.87%\n",
      "99.76% variance explained\n",
      "Accuracy: 50.87%\n",
      "99.96% variance explained\n",
      "Accuracy: 50.87%\n"
     ]
    }
   ],
   "source": [
    "#searching optimal number of WEIGHTED PC with k=20 \n",
    "for i in range(200,500,50):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "\n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "    #transform to PC space\n",
    "    estimator = PCA(n_components = i)\n",
    "    X_train = estimator.fit_transform(X_train)\n",
    "    X_test = estimator.transform(X_test)\n",
    "\n",
    "    variance_explained = estimator.explained_variance_ratio_\n",
    "    LAMBDA = np.diag(variance_explained) #diagonal matrix of loadings\n",
    "    print('{:.2%} variance explained'.format(np.sum(variance_explained)))\n",
    "    \n",
    "    X_train = np.dot(X_train, LAMBDA) #PC weighted by eigenvalue\n",
    "    X_test = np.dot(X_test, LAMBDA) #PC weighted by eigenvalue\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    accuracy = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
