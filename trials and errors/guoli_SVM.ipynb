{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMA: A Dataset For Music Analysis\n",
    "\n",
    "Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "* This notebook evalutates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on both audio and spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC # Support Vector Classification\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import utils\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liguo/Desktop/17-18Fall/2.CS229/5.Projects/Music_Analysis/github_analysis/fma-master/utils.py:220: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  'category', categories=SUBSETS, ordered=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "tracks = utils.load('tracks.csv') # (106574, 52)\n",
    "features = utils.load('features.csv') # (106574, 518)\n",
    "echonest = utils.load('echonest.csv') # (13129, 249)\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset\n",
    "We use 'medium' to build models. features_all: all 'features' data for <medium and small> subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518), (106574, 518))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# medium: 25000\n",
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium'] # track.index for <medium and small> subset\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "# features_all: features inner join echonest\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "\n",
    "# features_all: all 'features' data for <medium and small> subset.\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.34762</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.75889</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                   \\\n",
       "statistics    kurtosis                                                    \n",
       "number              01        02        03       04        05        06   \n",
       "track_id                                                                  \n",
       "2             7.180653  5.230309  0.249321  1.34762  1.482478  0.531371   \n",
       "\n",
       "feature                                               ...      tonnetz  \\\n",
       "statistics                                            ...          std   \n",
       "number            07        08        09        10    ...           04   \n",
       "track_id                                              ...                \n",
       "2           1.481593  2.691455  0.866868  1.341231    ...     0.054125   \n",
       "\n",
       "feature                             zcr                                     \\\n",
       "statistics                     kurtosis       max      mean    median  min   \n",
       "number            05        06       01        01        01        01   01   \n",
       "track_id                                                                     \n",
       "2           0.012226  0.012111  5.75889  0.459473  0.085629  0.071289  0.0   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "\n",
       "[1 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.34762</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.75889</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                   \\\n",
       "statistics    kurtosis                                                    \n",
       "number              01        02        03       04        05        06   \n",
       "track_id                                                                  \n",
       "2             7.180653  5.230309  0.249321  1.34762  1.482478  0.531371   \n",
       "\n",
       "feature                                               ...      tonnetz  \\\n",
       "statistics                                            ...          std   \n",
       "number            07        08        09        10    ...           04   \n",
       "track_id                                              ...                \n",
       "2           1.481593  2.691455  0.866868  1.341231    ...     0.054125   \n",
       "\n",
       "feature                             zcr                                     \\\n",
       "statistics                     kurtosis       max      mean    median  min   \n",
       "number            05        06       01        01        01        01   01   \n",
       "track_id                                                                     \n",
       "2           0.012226  0.012111  5.75889  0.459473  0.085629  0.071289  0.0   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "\n",
       "[1 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">echonest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">audio_features</th>\n",
       "      <th colspan=\"2\" halign=\"left\">metadata</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">temporal_features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>album_date</th>\n",
       "      <th>album_name</th>\n",
       "      <th>...</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.15931</td>\n",
       "      <td>165.922</td>\n",
       "      <td>0.576661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.992303</td>\n",
       "      <td>6.805694</td>\n",
       "      <td>0.23307</td>\n",
       "      <td>0.19288</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>0.06408</td>\n",
       "      <td>3.67696</td>\n",
       "      <td>3.61288</td>\n",
       "      <td>13.31669</td>\n",
       "      <td>262.929749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               echonest                                                    \\\n",
       "         audio_features                                                     \n",
       "           acousticness danceability    energy instrumentalness  liveness   \n",
       "track_id                                                                    \n",
       "2              0.416675     0.675894  0.634476         0.010628  0.177647   \n",
       "\n",
       "                                                                  ...      \\\n",
       "                                          metadata                ...       \n",
       "         speechiness    tempo   valence album_date album_name     ...       \n",
       "track_id                                                          ...       \n",
       "2            0.15931  165.922  0.576661        NaN        NaN     ...       \n",
       "\n",
       "                                                                           \\\n",
       "         temporal_features                                                  \n",
       "                       214       215      216      217       218      219   \n",
       "track_id                                                                    \n",
       "2                -1.992303  6.805694  0.23307  0.19288  0.027455  0.06408   \n",
       "\n",
       "                                                  \n",
       "                                                  \n",
       "              220      221       222         223  \n",
       "track_id                                          \n",
       "2         3.67696  3.61288  13.31669  262.929749  \n",
       "\n",
       "[1 rows x 249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipd.display(features_all.head(1))\n",
    "ipd.display(features.head(1))\n",
    "ipd.display(echonest.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (35): [' ', '-', '/', 'B', 'C', 'E', 'F', 'H', 'I', 'J', 'L', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'g', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'x', 'y', 'z']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "# get <tracks.index> for training data, validation set and test set to separate them. \n",
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "# genres in 'genre_top';\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "\n",
    "# genres in 'genres_all';\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multiple classifiers and feature sets\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracks: entire tracks sets including train/val/test sets;\n",
    "# features: entire feature sets used in models: features as X matrix;\n",
    "# columns: specified features subset extracted from 'features' used in model;\n",
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    # labels\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    # train, val, test: tracks.index for training data, validation set and test set. \n",
    "    # labels: genres in 'genre_top'/'genres_all';\n",
    "    y_train = enc.fit_transform(labels[train]) # labels\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    \n",
    "    # columns: columns used as features;\n",
    "    # features: entire features set;\n",
    "    X_train = features.loc[train, columns].as_matrix()\n",
    "    X_val = features.loc[val, columns].as_matrix()\n",
    "    X_test = features.loc[test, columns].as_matrix()\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # StandardScaler: Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False) \n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15\n"
     ]
    }
   ],
   "source": [
    "y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features, 'spectral_contrast', multi_label=False, verbose=False)\n",
    "print(min(y_test), max(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">album</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">track</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>...</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1126</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Street Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            album                                                          \\\n",
       "         comments        date_created date_released engineer favorites id   \n",
       "track_id                                                                    \n",
       "2               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
       "3               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
       "5               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
       "10              0 2008-11-26 01:45:08    2008-02-06      NaN         4  6   \n",
       "134             0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
       "\n",
       "                                                ...            track           \\\n",
       "         information listens producer tags      ...      information interest   \n",
       "track_id                                        ...                             \n",
       "2            <p></p>    6073      NaN   []      ...              NaN     4656   \n",
       "3            <p></p>    6073      NaN   []      ...              NaN     1470   \n",
       "5            <p></p>    6073      NaN   []      ...              NaN     1933   \n",
       "10               NaN   47632      NaN   []      ...              NaN    54881   \n",
       "134          <p></p>    6073      NaN   []      ...              NaN     1126   \n",
       "\n",
       "                                                                           \\\n",
       "         language_code                                            license   \n",
       "track_id                                                                    \n",
       "2                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "3                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "5                   en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "10                  en  Attribution-NonCommercial-NoDerivatives (aka M...   \n",
       "134                 en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "\n",
       "                                                               \n",
       "         listens lyricist number publisher tags         title  \n",
       "track_id                                                       \n",
       "2           1293      NaN      3       NaN   []          Food  \n",
       "3            514      NaN      4       NaN   []  Electric Ave  \n",
       "5           1151      NaN      6       NaN   []    This World  \n",
       "10         50135      NaN      1       NaN   []       Freeway  \n",
       "134          943      NaN      5       NaN   []  Street Music  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Single genre\n",
    "What we are going to do in this project.\n",
    "We use 'genre_top'(16 labels) as y, then output accuracy for various classifiers with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()).insert(0, 'dim') # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores, times\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVCrbf': SVC(kernel='rbf'),\n",
    "    'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "    'linSVC1': SVC(kernel=\"linear\"),\n",
    "    'linSVC2': LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "    'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "    'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    'NB': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_social': ('echonest', 'social_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "#    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "#    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "}\n",
    "\n",
    "# features.columns.levels[0]: \n",
    "#     Index(['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "#         'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "#         'spectral_rolloff', 'tonnetz', 'zcr'],\n",
    "#         dtype='object', name='feature')\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "    \n",
    "\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "# test_classifiers_features:\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipd.display(classifiers.keys()); \n",
    "ipd.display(feature_sets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipd.display(classifiers)\n",
    "ipd.display(feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipd.display(features.columns.levels[0])\n",
    "ipd.display(features.columns.levels[1])\n",
    "ipd.display(features.columns.levels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chroma_cens',\n",
       " 'chroma_cqt',\n",
       " 'chroma_stft',\n",
       " 'mfcc',\n",
       " 'rmse',\n",
       " 'spectral_bandwidth',\n",
       " 'spectral_centroid',\n",
       " 'spectral_contrast',\n",
       " 'spectral_rolloff',\n",
       " 'tonnetz',\n",
       " 'zcr']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "    \n",
    "# update: adds dictionary dict2's key-values pairs in to dict.\n",
    "feature_sets.update({ \n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "list(features.columns.levels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Single genres with all features\n",
    "\n",
    "Todo:\n",
    "* use above methods to deal with all features for different classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()).insert(0, 'dim') # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores_test = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    scores_train = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        \n",
    "        # Guzhiwei ********\n",
    "        model = SelectKBest(k=300)\n",
    "        fit = model.fit(X_train, y_train)\n",
    "        X_train = fit.transform(X_train)\n",
    "        X_test = fit.transform(X_test)\n",
    "        \n",
    "        # Guzhiwei *********\n",
    "        \n",
    "        scores_test.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        scores_train.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "#         n_sample_train = [  58,  495,  142,   13, 5050, 1801, 1215, 1761, 1045,  814,  306,\n",
    "#          408,  945, 5681,   94,   94]\n",
    "#         n_sample_test = [  8,  62,  18,   6, 632, 225, 152, 220, 174, 102,  39,  51, 119,\n",
    "#         711,  42,  12]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            # train the model;\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # for training data\n",
    "            Y_predict_train = clf.predict(X_train)\n",
    "            Precision_recall_train = precision_recall_fscore_support(y_train, Y_predict_train)\n",
    "            score_train = clf.score(X_train, y_train) # accuracy for function clf.\n",
    "            scores_train.loc[fset_name, clf_name] = score_train\n",
    "            confusion_train = confusion_matrix(y_train, Y_predict_train, labels=labels) #, sample_weight=Precision_recall_train[3])\n",
    "            \n",
    "            # for test data\n",
    "            Y_predict_test = clf.predict(X_test)\n",
    "            Precision_recall_test = precision_recall_fscore_support(y_test, Y_predict_test)\n",
    "            score_test = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            scores_test.loc[fset_name, clf_name] = score_test\n",
    "            confusion_test = confusion_matrix(y_test, Y_predict_test, labels=labels) #, sample_weight=Precision_recall_test[3])\n",
    "            \n",
    "            # for time\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores_test, scores_train, times, Precision_recall_train, Precision_recall_test, confusion_train, confusion_test\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9824141cbc324877806c7d2cdf8f69c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='features', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_69eb8828_de03_11e7_aba8_8c85901efc55row0_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_69eb8828_de03_11e7_aba8_8c85901efc55\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >dim</th> \n",
       "        <th class=\"col_heading level0 col1\" >linSVC2</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_69eb8828_de03_11e7_aba8_8c85901efc55level0_row0\" class=\"row_heading level0 row0\" >all</th> \n",
       "        <td id=\"T_69eb8828_de03_11e7_aba8_8c85901efc55row0_col0\" class=\"data row0 col0\" >300</td> \n",
       "        <td id=\"T_69eb8828_de03_11e7_aba8_8c85901efc55row0_col1\" class=\"data row0 col1\" >61.45%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x129262898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_69ec5658_de03_11e7_9e59_8c85901efc55row0_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_69ec5658_de03_11e7_9e59_8c85901efc55\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >dim</th> \n",
       "        <th class=\"col_heading level0 col1\" >linSVC2</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_69ec5658_de03_11e7_9e59_8c85901efc55level0_row0\" class=\"row_heading level0 row0\" >all</th> \n",
       "        <td id=\"T_69ec5658_de03_11e7_9e59_8c85901efc55row0_col0\" class=\"data row0 col0\" >300</td> \n",
       "        <td id=\"T_69ec5658_de03_11e7_9e59_8c85901efc55row0_col1\" class=\"data row0 col1\" >67.37%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x129262cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_69ecb10a_de03_11e7_b6c9_8c85901efc55\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >linSVC2</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_69ecb10a_de03_11e7_b6c9_8c85901efc55level0_row0\" class=\"row_heading level0 row0\" >all</th> \n",
       "        <td id=\"T_69ecb10a_de03_11e7_b6c9_8c85901efc55row0_col0\" class=\"data row0 col0\" >43.9244</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x127a3d198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.71551724,  1.        ,  0.        ,  0.65624013,\n",
       "         0.55215827,  0.63233083,  0.67056758,  0.59104938,  0.69959677,\n",
       "         0.74358974,  0.93055556,  0.625     ,  0.70241099,  0.        ,\n",
       "         0.71794872]),\n",
       " array([ 0.        ,  0.83838384,  0.01408451,  0.        ,  0.82257426,\n",
       "         0.34092171,  0.69218107,  0.65076661,  0.36650718,  0.42628993,\n",
       "         0.18954248,  0.98529412,  0.02116402,  0.88206302,  0.        ,\n",
       "         0.29787234]),\n",
       " array([ 0.        ,  0.77209302,  0.02777778,  0.        ,  0.73005272,\n",
       "         0.42155853,  0.66090373,  0.66051873,  0.45245127,  0.52977099,\n",
       "         0.30208333,  0.95714286,  0.04094166,  0.78205228,  0.        ,\n",
       "         0.42105263]),\n",
       " array([  58,  495,  142,   13, 5050, 1801, 1215, 1761, 1045,  814,  306,\n",
       "         408,  945, 5681,   94,   94]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.72368421,  0.        ,  0.        ,  0.659601  ,\n",
       "         0.41875   ,  0.26219512,  0.73300971,  0.36065574,  0.42372881,\n",
       "         0.86666667,  0.79032258,  0.        ,  0.65244537,  0.        ,  0.        ]),\n",
       " array([ 0.        ,  0.88709677,  0.        ,  0.        ,  0.83702532,\n",
       "         0.29777778,  0.28289474,  0.68636364,  0.12643678,  0.24509804,\n",
       "         0.33333333,  0.96078431,  0.        ,  0.88185654,  0.        ,  0.        ]),\n",
       " array([ 0.        ,  0.79710145,  0.        ,  0.        ,  0.73779637,\n",
       "         0.34805195,  0.2721519 ,  0.70892019,  0.18723404,  0.31055901,\n",
       "         0.48148148,  0.86725664,  0.        ,  0.75      ,  0.        ,  0.        ]),\n",
       " array([  8,  62,  18,   6, 632, 225, 152, 220, 174, 102,  39,  51, 119,\n",
       "        711,  42,  12]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = {\n",
    "#    'LR': LogisticRegression(),\n",
    "    # Inverse of regularization strength; must be a positive float. Like in support vector machines, \n",
    "    # smaller values specify stronger regularization.\n",
    "#    'LR_l2': LogisticRegression(penalty='l1', C=0.3)\n",
    "#     'NN': MLPClassifier(hidden_layer_sizes=(280, 18, 16), activation='relu', alpha=2, max_iter=200)\n",
    "#     'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "#     'SVCrbf': SVC(kernel='rbf', C=1.6),\n",
    "#     'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "#     'linSVC1': SVC(kernel=\"linear\"),\n",
    "#     'linSVC2': LinearSVC(),\n",
    "   'linSVC2': LinearSVC(penalty='l2', loss='squared_hinge', \n",
    "                           dual=True, tol=0.0001, C=0.009, multi_class='ovr', \n",
    "                           fit_intercept=True, intercept_scaling=1, \n",
    "                           class_weight=None, verbose=0, random_state=None, \n",
    "                           max_iter=500),\n",
    "#     'linSVC2': LinearSVC(penalty='l1', loss='squared_hinge', dual=False,\n",
    "#                        tol=1e-3, C=0.1, multi_class='ovr', \n",
    "#                            fit_intercept=True, intercept_scaling=1, \n",
    "#                            class_weight=None, verbose=0, random_state=None, \n",
    "#                            max_iter=1000),\n",
    "#     #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "#     'DT': DecisionTreeClassifier(max_depth=5),\n",
    "#     'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "#     'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "#     'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "#     'NB': GaussianNB(),\n",
    "#     'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "# ['mfcc','std']: indicate level[0]: 'mfcc', level[1]: 'std';\n",
    "# ['mfcc', 'spectral_contrast']: idicate 2 different level[0]: 'mfcc', 'spectral_contrast'\n",
    "\n",
    "# feature_sets = features.columns.levels[0];\n",
    "feature_sets = {\n",
    "     'all': ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "           'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "           'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "}\n",
    "# #    'echonest_audio': ('echonest', 'audio_features'),\n",
    "# #    'echonest_social': ('echonest', 'social_features'),\n",
    "# #    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "# #    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "# #    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "# }\n",
    "\n",
    "# features.columns.levels[0]: \n",
    "#     Index(['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "#         'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "#         'spectral_rolloff', 'tonnetz', 'zcr'],\n",
    "#         dtype='object', name='feature')\n",
    "# for name in features.columns.levels[0]:\n",
    "#     feature_sets[name] = name\n",
    "    \n",
    "\n",
    "# feature_sets.update({\n",
    "#     'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "#     'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "#     'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "#     'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "#     'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "#     'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "#     'all_non-echonest': list(features.columns.levels[0])\n",
    "# })\n",
    "\n",
    "# test_classifiers_features:\n",
    "# scores.test, scores.train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "scores_test, scores_train, times, Precision_recall_train, Precision_recall_test, confusion_train, confusion_test = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores_test))\n",
    "ipd.display(format_scores(scores_train))\n",
    "#ipd.display(format_scores(score))\n",
    "ipd.display(times.style.format('{:.4f}'))\n",
    "ipd.display(Precision_recall_train)\n",
    "ipd.display(Precision_recall_test)\n",
    "\n",
    "# Score for LR model with all features: 61.10% (dim: 518)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipd.display(confusion_train)\n",
    "ipd.display(confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn import svm, datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # import some data to play with\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "# class_names = iris.target_names\n",
    "\n",
    "# # Split the data into a training set and a test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# # Run classifier, using a model that is too regularized (C too low) to see\n",
    "# # the impact on the results\n",
    "# classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "# y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# plt.figure()\n",
    "# plot1 = plot_confusion_matrix(confusion_train, classes=[i for i in \"ABCDEFGHIJKLMNOP\"], normalize=True,\n",
    "#                       title='Confusion matrix for training data: with normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot2 = plot_confusion_matrix(confusion_test, classes=[i for i in \"ABCDEFGHIJKLMNOP\"], normalize=True,\n",
    "#                       title='Confusion matrix for test data: with normalization')\n",
    "# #plt.show()\n",
    "\n",
    "# pp = PdfPages('foo.pdf')\n",
    "# pp.savefig(plot1)\n",
    "# pp.savefig(plot2)\n",
    "# pp.close()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## normalize the matrices\n",
    "\n",
    "df_test = pd.DataFrame(confusion_test, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "df_test_norm = (df_test-df_test.mean())/df_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.DataFrame(confusion_train, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "# df_train_norm = (df_train-df_train.mean())/df_train.std()*100\n",
    "df_train_norm = df_train/(df_train.mean()+0.000001)\n",
    "\n",
    "# df_cm = pd.DataFrame(confusion_train, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "#                   columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_train, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_train_norm, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(confusion_test, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "# df_test_norm = (df_test-df_test.mean())/df_test.std()\n",
    "df_test_norm = df_test/(df_test.mean()+0.00001)\n",
    "\n",
    "# df_cm_test = pd.DataFrame(df_test, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "#                   columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_test, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_test_norm, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features.loc[:,feature_sets]\n",
    "#name, fset = tqdm_notebook(feature_sets.items(), desc='features')\n",
    "features.loc[:, ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "             'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "             'spectral_rolloff', 'tonnetz', 'zcr']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 SVM with regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()) # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores_test = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    scores_train = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1,\n",
    "                                    average=None, warn_for=(‘precision’, ’recall’, ’f-score’), \n",
    "                                    sample_weight=None)\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores_test.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        scores_train.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score_test = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            score_train = clf.score(X_train, y_train) # accuracy for function clf.\n",
    "            scores_test.loc[fset_name, clf_name] = score_test\n",
    "            scores_train.loc[fset_name, clf_name] = score_train\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores_test, scores_train, times\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.estimators import svm\n",
    "classifiers = {\n",
    "#    'LR': LogisticRegression(),\n",
    "#     'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "#     'SVCrbf': SVC(kernel='rbf'),\n",
    "#     'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "#     'linSVC1': SVC(kernel=\"linear\"),\n",
    "#    'linSVC2': LinearSVC(),\n",
    "#       'linSVC2': LinearSVC(penalty='l2', loss='squared_hinge', \n",
    "#                            dual=True, tol=0.0001, C=0.008, multi_class='ovr', \n",
    "#                            fit_intercept=True, intercept_scaling=1, \n",
    "#                            class_weight=None, verbose=0, random_state=None, \n",
    "#                            max_iter=1000),\n",
    "#     'linSVC2': LinearSVC(penalty='l1', loss='squared_hinge', dual=False,\n",
    "#                        tol=1e-3, C=0.08, multi_class='ovr', \n",
    "#                            fit_intercept=True, intercept_scaling=1, \n",
    "#                            class_weight=None, verbose=0, random_state=None, \n",
    "#                            max_iter=1000),\n",
    "#     #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "#     'DT': DecisionTreeClassifier(max_depth=5),\n",
    "#     'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "#     'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "#     'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "#     'NB': GaussianNB(),\n",
    "#     'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "# ['mfcc','std']: indicate level[0]: 'mfcc', level[1]: 'std';\n",
    "# ['mfcc', 'spectral_contrast']: idicate 2 different level[0]: 'mfcc', 'spectral_contrast'\n",
    "\n",
    "# feature_sets = features.columns.levels[0];\n",
    "feature_sets = {\n",
    "     'all': ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "           'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "           'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "}\n",
    "# #    'echonest_audio': ('echonest', 'audio_features'),\n",
    "# #    'echonest_social': ('echonest', 'social_features'),\n",
    "# #    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "# #    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "# #    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "# }\n",
    "\n",
    "# features.columns.levels[0]: \n",
    "#     Index(['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "#         'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "#         'spectral_rolloff', 'tonnetz', 'zcr'],\n",
    "#         dtype='object', name='feature')\n",
    "# for name in features.columns.levels[0]:\n",
    "#     feature_sets[name] = name\n",
    "    \n",
    "\n",
    "# feature_sets.update({\n",
    "#     'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "#     'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "#     'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "#     'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "#     'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "#     'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "#     'all_non-echonest': list(features.columns.levels[0])\n",
    "# })\n",
    "\n",
    "# test_classifiers_features:\n",
    "# scores.test, scores.train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "scores_test, scores_train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores_test))\n",
    "ipd.display(format_scores(scores_train))\n",
    "#ipd.display(format_scores(score))\n",
    "ipd.display(times.style.format('{:.4f}'))\n",
    "\n",
    "# Score for LR model with all features: 61.10% (dim: 518)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Learning Curve\n",
    "\n",
    "Todo:\n",
    "* Learning curve for both SVM and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Multiple genres\n",
    "\n",
    "Todo:\n",
    "* Ignore rare genres? Count them higher up in the genre tree? On the other hand it's not much tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    #LogisticRegression(),\n",
    "    'LR': OneVsRestClassifier(LogisticRegression()),\n",
    "    'SVC': OneVsRestClassifier(SVC()),\n",
    "    'MLP': MLPClassifier(max_iter=700),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "    'mfcc': 'mfcc',\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "}\n",
    "\n",
    "# multi_label: use 'genres_all'(151) as y; \n",
    "scores, times = test_classifiers_features(classifiers, feature_sets, multi_label=True)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Deep learning on raw audio\n",
    "\n",
    "Other architectures:\n",
    "* [Learning Features of Music from Scratch (MusicNet)](https://arxiv.org/abs/1611.09827), John Thickstun, Zaid Harchaoui, Sham Kakade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_onehot = MultiLabelBinarizer().fit_transform(tracks['track', 'genres_top'])\n",
    "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio samples in parallel using `multiprocessing` so as to maximize CPU usage when decoding MP3s and making some optional pre-processing. There are multiple ways to load a waveform from a compressed MP3:\n",
    "* librosa uses audioread in the backend which can use many native libraries, e.g. ffmpeg\n",
    "    * resampling is very slow --> use `kaiser_fast`\n",
    "    * does not work with multi-processing, for keras `fit_generator()`\n",
    "* pydub is a high-level interface for audio modification, uses ffmpeg to load\n",
    "    * store a temporary `.wav`\n",
    "* directly pipe ffmpeg output\n",
    "    * fastest method\n",
    "* [pyAV](https://github.com/mikeboers/PyAV) may be a fastest alternative by linking to ffmpeg libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just be sure that everything is fine. Multiprocessing is tricky to debug.\n",
    "utils.FfmpegLoader().load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, utils.FfmpegLoader())\n",
    "SampleLoader(train, batch_size=2).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras parameters.\n",
    "NB_WORKER = len(os.sched_getaffinity(0))  # number of usables CPUs\n",
    "params = {'pickle_safe': True, 'nb_worker': NB_WORKER, 'max_q_size': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fully connected neural network\n",
    "\n",
    "* Two layers with 10 hiddens is no better than random, ~11%.\n",
    "\n",
    "Optimize data loading to be CPU / GPU bound, not IO bound. Larger batches means reduced training time, so increase batch time until memory exhaustion. Number of workers and queue size have no influence on speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=2000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "print('Dimensionality: {}'.format(loader.shape))\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(output_dim=1000, input_shape=loader.shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=64), train.size, nb_epoch=2, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=64), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=64), test.size, **params)\n",
    "#Y = model.predict_generator(SampleLoader(test, batch_size=64), test.size, **params);\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convolutional neural network\n",
    "\n",
    "* Architecture: [End-to-end learning for music audio](http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7014-dieleman.pdf), Sander Dieleman, Benjamin Schrauwen.\n",
    "* Missing: track segmentation and class averaging (majority voting)\n",
    "* Compared with log-scaled mel-spectrograms instead of strided convolution as first layer.\n",
    "* Larger net: http://benanne.github.io/2014/08/05/spotify-cnns.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=16000)\n",
    "#loader = utils.LibrosaLoader(sampling_rate=16000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((-1, 1), input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv1D(128, 512, subsample_length=512))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=10), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=10), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=10), test.size, **params)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Deep learning on extracted audio features\n",
    "\n",
    "Look at:\n",
    "* Pre-processing in Keras: https://github.com/keunwoochoi/kapre\n",
    "* Convolutional Recurrent Neural Networks for Music Classification: https://github.com/keunwoochoi/icassp_2017\n",
    "* Music Auto-Tagger: https://github.com/keunwoochoi/music-auto_tagging-keras\n",
    "* Pre-processor: https://github.com/bmcfee/pumpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ConvNet on MFCC\n",
    "\n",
    "* Architecture: [Automatic Musical Pattern Feature Extraction Using Convolutional Neural Network](http://www.iaeng.org/publication/IMECS2010/IMECS2010_pp546-550.pdf), Tom LH. Li, Antoni B. Chan and Andy HW. Chun\n",
    "* Missing: track segmentation and majority voting.\n",
    "* Best seen: 17.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MfccLoader(utils.Loader):\n",
    "    raw_loader = utils.FfmpegLoader(sampling_rate=22050)\n",
    "    #shape = (13, 190)  # For segmented tracks.\n",
    "    shape = (13, 2582)\n",
    "    def load(self, filename):\n",
    "        import librosa\n",
    "        x = self.raw_loader.load(filename)\n",
    "        # Each MFCC frame spans 23ms on the audio signal with 50% overlap with the adjacent frames.\n",
    "        mfcc = librosa.feature.mfcc(x, sr=22050, n_mfcc=13, n_fft=512, hop_length=256)\n",
    "        return mfcc\n",
    "\n",
    "loader = MfccLoader()\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "loader.load(utils.get_audio_path(AUDIO_DIR, 2))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((*loader.shape, 1),  input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(3, 13, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(15, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(65, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(1e-3)#lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=16), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=16), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=16), test.size, **params)\n",
    "#Y = model.predict_generator(loader, test.size, pickle_safe=True, nb_worker=NB_WORKER, max_q_size=5)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
