{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMA: A Dataset For Music Analysis\n",
    "\n",
    "Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "* This notebook evalutates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on both audio and spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC # Support Vector Classification\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import utils\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liguo/Desktop/17-18Fall/2.CS229/5.Projects/Music_Analysis/github_analysis/fma-master/utils.py:220: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  'category', categories=SUBSETS, ordered=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "tracks = utils.load('data/tracks.csv') # (106574, 52)\n",
    "features = utils.load('data/features.csv') # (106574, 518)\n",
    "echonest = utils.load('data/echonest.csv') # (13129, 249)\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset\n",
    "We use 'medium' to build models. features_all: all 'features' data for <medium and small> subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518), (106574, 518))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# medium: 25000\n",
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium'] # track.index for <medium and small> subset\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "# features_all: features inner join echonest\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "\n",
    "# features_all: all 'features' data for <medium and small> subset.\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.34762</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.75889</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                   \\\n",
       "statistics    kurtosis                                                    \n",
       "number              01        02        03       04        05        06   \n",
       "track_id                                                                  \n",
       "2             7.180653  5.230309  0.249321  1.34762  1.482478  0.531371   \n",
       "\n",
       "feature                                               ...      tonnetz  \\\n",
       "statistics                                            ...          std   \n",
       "number            07        08        09        10    ...           04   \n",
       "track_id                                              ...                \n",
       "2           1.481593  2.691455  0.866868  1.341231    ...     0.054125   \n",
       "\n",
       "feature                             zcr                                     \\\n",
       "statistics                     kurtosis       max      mean    median  min   \n",
       "number            05        06       01        01        01        01   01   \n",
       "track_id                                                                     \n",
       "2           0.012226  0.012111  5.75889  0.459473  0.085629  0.071289  0.0   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "\n",
       "[1 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.34762</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.75889</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                   \\\n",
       "statistics    kurtosis                                                    \n",
       "number              01        02        03       04        05        06   \n",
       "track_id                                                                  \n",
       "2             7.180653  5.230309  0.249321  1.34762  1.482478  0.531371   \n",
       "\n",
       "feature                                               ...      tonnetz  \\\n",
       "statistics                                            ...          std   \n",
       "number            07        08        09        10    ...           04   \n",
       "track_id                                              ...                \n",
       "2           1.481593  2.691455  0.866868  1.341231    ...     0.054125   \n",
       "\n",
       "feature                             zcr                                     \\\n",
       "statistics                     kurtosis       max      mean    median  min   \n",
       "number            05        06       01        01        01        01   01   \n",
       "track_id                                                                     \n",
       "2           0.012226  0.012111  5.75889  0.459473  0.085629  0.071289  0.0   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "\n",
       "[1 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">echonest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">audio_features</th>\n",
       "      <th colspan=\"2\" halign=\"left\">metadata</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">temporal_features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>album_date</th>\n",
       "      <th>album_name</th>\n",
       "      <th>...</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.15931</td>\n",
       "      <td>165.922</td>\n",
       "      <td>0.576661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.992303</td>\n",
       "      <td>6.805694</td>\n",
       "      <td>0.23307</td>\n",
       "      <td>0.19288</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>0.06408</td>\n",
       "      <td>3.67696</td>\n",
       "      <td>3.61288</td>\n",
       "      <td>13.31669</td>\n",
       "      <td>262.929749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               echonest                                                    \\\n",
       "         audio_features                                                     \n",
       "           acousticness danceability    energy instrumentalness  liveness   \n",
       "track_id                                                                    \n",
       "2              0.416675     0.675894  0.634476         0.010628  0.177647   \n",
       "\n",
       "                                                                  ...      \\\n",
       "                                          metadata                ...       \n",
       "         speechiness    tempo   valence album_date album_name     ...       \n",
       "track_id                                                          ...       \n",
       "2            0.15931  165.922  0.576661        NaN        NaN     ...       \n",
       "\n",
       "                                                                           \\\n",
       "         temporal_features                                                  \n",
       "                       214       215      216      217       218      219   \n",
       "track_id                                                                    \n",
       "2                -1.992303  6.805694  0.23307  0.19288  0.027455  0.06408   \n",
       "\n",
       "                                                  \n",
       "                                                  \n",
       "              220      221       222         223  \n",
       "track_id                                          \n",
       "2         3.67696  3.61288  13.31669  262.929749  \n",
       "\n",
       "[1 rows x 249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipd.display(features_all.head(1))\n",
    "ipd.display(features.head(1))\n",
    "ipd.display(echonest.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (35): [' ', '-', '/', 'B', 'C', 'E', 'F', 'H', 'I', 'J', 'L', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'g', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'x', 'y', 'z']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "# get <tracks.index> for training data, validation set and test set to separate them. \n",
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "#test = tracks.index[tracks['set', 'split'] != 'training']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "# genres in 'genre_top';\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "\n",
    "# genres in 'genres_all';\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multiple classifiers and feature sets\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracks: entire tracks sets including train/val/test sets;\n",
    "# features: entire feature sets used in models: features as X matrix;\n",
    "# columns: specified features subset extracted from 'features' used in model;\n",
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    # labels\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    # train, val, test: tracks.index for training data, validation set and test set. \n",
    "    # labels: genres in 'genre_top'/'genres_all';\n",
    "    y_train = enc.fit_transform(labels[train]) # labels\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    \n",
    "    # columns: columns used as features;\n",
    "    # features: entire features set;\n",
    "    X_train = features.loc[train, columns].as_matrix()\n",
    "    X_val = features.loc[val, columns].as_matrix()\n",
    "    X_test = features.loc[test, columns].as_matrix()\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # StandardScaler: Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False) \n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Single genre\n",
    "What we are going to do in this project.\n",
    "We use 'genre_top'(16 labels) as y, then output accuracy for various classifiers with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features, 'spectral_contrast', multi_label=False, verbose=False)\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()).insert(0, 'dim') # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores, times\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipd.display(classifiers.keys()); \n",
    "ipd.display(feature_sets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipd.display(classifiers)\n",
    "ipd.display(feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipd.display(features.columns.levels[0])\n",
    "ipd.display(features.columns.levels[1])\n",
    "ipd.display(features.columns.levels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "    \n",
    "# update: adds dictionary dict2's key-values pairs in to dict.\n",
    "feature_sets.update({ \n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "list(features.columns.levels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rogistic Regression + Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())    \n",
    "    columns = ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "             'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "             'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "    \n",
    "    y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features, columns, multi_label=False, verbose=False);\n",
    "    \n",
    "\n",
    "    #print(\"x size, y size: \", X_train_all.shape, y_train.shape)\n",
    "    model = SelectKBest(k=275)\n",
    "    fit = model.fit(X_train, y_train)\n",
    "    X_train = fit.transform(X_train)\n",
    "    X_test = fit.transform(X_test)\n",
    "    \n",
    "    M = X_train.shape[0]/10\n",
    "    X_learning = np.empty(10)\n",
    "    Y_train_curve = np.empty(10)\n",
    "    Y_test_curve = np.empty(10)\n",
    "    for j in range(10):\n",
    "        MJ = int(M*j)\n",
    "        X_train_this = np.delete(X_train,np.s_[0:MJ],axis=0)\n",
    "        Y_train_this = np.delete(y_train,np.s_[0:MJ],axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "        w = np.zeros([X_train_this.shape[1], 16])   #len(np.unique(Y_train_this)=16\n",
    "        lam = 1\n",
    "        iterations = 5000\n",
    "        learningRate = 1e-4\n",
    "        losses = []\n",
    "        \n",
    "        \n",
    "        for i in range(0,iterations):\n",
    "            loss, grad = getLoss(w,X_train_this,Y_train_this,lam)\n",
    "            losses.append(loss)\n",
    "            w = w - (learningRate * grad)\n",
    "\n",
    "            \n",
    "        #print(loss)\n",
    "        \n",
    "        X_learning[j] = (10-j)*M\n",
    "        Y_train_curve[j] = getAccuracy(X_train_this,Y_train_this,w)\n",
    "        Y_test_curve[j] = getAccuracy(X_test,y_test,w)\n",
    "        print('Training Accuracy:', Y_train_curve[j])\n",
    "        print('Test Accuracy:', Y_test_curve[j])\n",
    "      \n",
    "    plt.plot(X_learning, Y_train_curve, linewidth = 2.0, color = 'red')\n",
    "    plt.plot(X_learning, Y_test_curve, linewidth = 2.0, color = 'blue')\n",
    "    plt.show()\n",
    "    #print('Training Accuracy:', getAccuracy(X_train,y_train,w))\n",
    "    #print('Test Accuracy:', getAccuracy(X_test,y_test,w))\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "test_classifiers_features(classifiers, feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + PCA + Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=141, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_test, y_test)\n",
    "print('Accuracy: {:.2%}'.format(score))\n",
    "\n",
    "\n",
    "#searching optimal k without PCA transformation\n",
    "accuracy = []\n",
    "for i in range(1, 10):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    \n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "    print('{} features, {} classes'.format(X_train.shape[1], np.unique(y_train).size))\n",
    "    \n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(score))\n",
    "    accuracy.append(score)\n",
    "    \n",
    "#searching optimal number of PC with k=20\n",
    "accuracy = []\n",
    "for i in range(125, 145):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "\n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "    #transform to PC space\n",
    "    estimator = PCA(n_components = i)\n",
    "    X_train = estimator.fit_transform(X_train)\n",
    "    #variance_explained = estimator.explained_variance_ratio_\n",
    "    #print('{:.2%} variance explained'.format(np.sum(variance_explained)))\n",
    "    X_test = estimator.transform(X_test)\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    accuracy = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy))\n",
    "    \n",
    "    \n",
    "#search for optimal k with 200 selected feature \n",
    "medium = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "X_train = features.loc[medium & train,:]\n",
    "X_test = features.loc[medium & test,:]\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "model = SelectKBest(k=169)\n",
    "fit = model.fit(X_train, y_train)\n",
    "X_train = fit.transform(X_train)\n",
    "X_test = fit.transform(X_test)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "neigh.fit(X_train, y_train)\n",
    "score = neigh.score(X_train, y_train)\n",
    "print('Accuracy: {:.2%}'.format(score))\n",
    "\n",
    "\n",
    "#search for optimal feature size with k = 20\n",
    "medium = tracks['set', 'subset'] <= 'medium'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "#searching optimal k without PCA transformation\n",
    "for i in range(160, 170):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "\n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    model = SelectKBest(k=i)\n",
    "    fit = model.fit(X_train, y_train)\n",
    "    X_train = fit.transform(X_train)\n",
    "    X_test = fit.transform(X_test)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(score))\n",
    "    \n",
    "    \n",
    "\n",
    "#searching optimal number of WEIGHTED PC with k=20 \n",
    "for i in range(200,500,50):\n",
    "    y_train = tracks.loc[medium & train, ('track', 'genre_top')]\n",
    "    y_train = skl.preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "    y_test = tracks.loc[medium & test, ('track', 'genre_top')]\n",
    "    y_test = skl.preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "    X_train = features.loc[medium & train,:]\n",
    "    X_test = features.loc[medium & test,:]\n",
    "\n",
    "    # Be sure training samples are shuffled.\n",
    "    X_train, y_train = skl.utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "    #transform to PC space\n",
    "    estimator = PCA(n_components = i)\n",
    "    X_train = estimator.fit_transform(X_train)\n",
    "    X_test = estimator.transform(X_test)\n",
    "\n",
    "    variance_explained = estimator.explained_variance_ratio_\n",
    "    LAMBDA = np.diag(variance_explained) #diagonal matrix of loadings\n",
    "    print('{:.2%} variance explained'.format(np.sum(variance_explained)))\n",
    "    \n",
    "    X_train = np.dot(X_train, LAMBDA) #PC weighted by eigenvalue\n",
    "    X_test = np.dot(X_test, LAMBDA) #PC weighted by eigenvalue\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "    neigh.fit(X_train, y_train)\n",
    "    accuracy = neigh.score(X_test, y_test)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network + Model selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "columns = ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "             'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "             'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "    \n",
    "y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features, columns, multi_label=False, verbose=False);\n",
    "\n",
    "model = SelectKBest(k=300)\n",
    "fit = model.fit(X_train, y_train)\n",
    "X_train = fit.transform(X_train)\n",
    "X_test = fit.transform(X_val)\n",
    "y_test = y_val\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(100,input_dim=300),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(33,input_dim=100),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(16),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(y_train, num_classes=16)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(X_train, one_hot_labels, epochs=20, batch_size=200)\n",
    "ylabels = keras.utils.to_categorical(y_test, num_classes=16)\n",
    "model.evaluate(X_test, ylabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network + PCA + learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = PCA(n_components=250).fit_transform(X_train)\n",
    "X_test = PCA(n_components=250).fit_transform(X_train)\n",
    "M = X_train.shape[0]/10\n",
    "X_learning = np.empty(10)\n",
    "Y_train_curve = np.empty(10)\n",
    "Y_test_curve = np.empty(10)\n",
    "for j in range(10):\n",
    "    MJ = int(M*j)\n",
    "    \n",
    "    model = Sequential([\n",
    "    Dense(100,input_dim=250),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(32,input_dim=100),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(16),\n",
    "    Activation('softmax'),\n",
    "\n",
    "    ])\n",
    "\n",
    "# For a multi-class classification problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train_this = np.delete(X_train,np.s_[0:MJ],axis=0)\n",
    "    Y_train_this = np.delete(y_train,np.s_[0:MJ],axis=0)\n",
    "    X_learning[j] = (10-j)*M\n",
    "    \n",
    "    one_hot_labels = keras.utils.to_categorical(Y_train_this, num_classes=16)\n",
    "    trainingObj = model.fit(X_train_this, one_hot_labels, epochs=20, batch_size=200)\n",
    "    Y_train_curve[j] = trainingObj.history['acc'][19]   \n",
    "    ylabels = keras.utils.to_categorical(y_test, num_classes=16)\n",
    "    testingObj = model.evaluate(X_test, ylabels)\n",
    "    Y_test_curve[j] = testingObj[1]\n",
    "    \n",
    "\n",
    "plt.plot(X_learning, Y_train_curve, linewidth = 2.0, color = 'red')\n",
    "plt.plot(X_learning, Y_test_curve, linewidth = 2.0, color = 'blue')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM_rbf + Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()).insert(0, 'dim') # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores_test = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    scores_train = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        \n",
    "        # Guzhiwei ********\n",
    "        model = SelectKBest(k=200)\n",
    "        fit = model.fit(X_train, y_train)\n",
    "        X_train = fit.transform(X_train)\n",
    "        X_test = fit.transform(X_test)\n",
    "        \n",
    "        # Guzhiwei *********\n",
    "        \n",
    "        scores_test.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        scores_train.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            # train the model;\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # for training data\n",
    "            Y_predict_train = clf.predict(X_train)\n",
    "            Precision_recall_train = precision_recall_fscore_support(y_train, Y_predict_train)\n",
    "            score_train = clf.score(X_train, y_train) # accuracy for function clf.\n",
    "            scores_train.loc[fset_name, clf_name] = score_train\n",
    "            confusion_train = confusion_matrix(y_train, Y_predict_train, labels=labels) #, sample_weight=Precision_recall_train[3])\n",
    "            \n",
    "            # for test data\n",
    "            Y_predict_test = clf.predict(X_test)\n",
    "            Precision_recall_test = precision_recall_fscore_support(y_test, Y_predict_test)\n",
    "            score_test = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            scores_test.loc[fset_name, clf_name] = score_test\n",
    "            confusion_test = confusion_matrix(y_test, Y_predict_test, labels=labels) #, sample_weight=Precision_recall_test[3])\n",
    "            \n",
    "            # for time\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores_test, scores_train, times, Precision_recall_train, Precision_recall_test, confusion_train, confusion_test\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b28344e974433b8934d6c04a9daef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='features', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ad75e834_e1ec_11e7_8083_8c85901efc55row0_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_ad75e834_e1ec_11e7_8083_8c85901efc55\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >dim</th> \n",
       "        <th class=\"col_heading level0 col1\" >SVCrbf</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_ad75e834_e1ec_11e7_8083_8c85901efc55level0_row0\" class=\"row_heading level0 row0\" >all</th> \n",
       "        <td id=\"T_ad75e834_e1ec_11e7_8083_8c85901efc55row0_col0\" class=\"data row0 col0\" >200</td> \n",
       "        <td id=\"T_ad75e834_e1ec_11e7_8083_8c85901efc55row0_col1\" class=\"data row0 col1\" >63.39%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11ec25080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ad77e934_e1ec_11e7_b9c1_8c85901efc55row0_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_ad77e934_e1ec_11e7_b9c1_8c85901efc55\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >dim</th> \n",
       "        <th class=\"col_heading level0 col1\" >SVCrbf</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_ad77e934_e1ec_11e7_b9c1_8c85901efc55level0_row0\" class=\"row_heading level0 row0\" >all</th> \n",
       "        <td id=\"T_ad77e934_e1ec_11e7_b9c1_8c85901efc55row0_col0\" class=\"data row0 col0\" >200</td> \n",
       "        <td id=\"T_ad77e934_e1ec_11e7_b9c1_8c85901efc55row0_col1\" class=\"data row0 col1\" >76.45%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11ec25438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_ad78667a_e1ec_11e7_bce3_8c85901efc55\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >SVCrbf</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_ad78667a_e1ec_11e7_bce3_8c85901efc55level0_row0\" class=\"row_heading level0 row0\" >all</th> \n",
       "        <td id=\"T_ad78667a_e1ec_11e7_bce3_8c85901efc55row0_col0\" class=\"data row0 col0\" >261.4798</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11ec25ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.87025948,  1.        ,  0.        ,  0.72935706,\n",
       "         0.72789969,  0.74065041,  0.78636364,  0.73413174,  0.81639929,\n",
       "         0.85430464,  0.99502488,  0.72687225,  0.78165473,  0.        ,\n",
       "         0.796875  ]),\n",
       " array([ 0.        ,  0.88080808,  0.11267606,  0.        ,  0.90079208,\n",
       "         0.64464187,  0.74979424,  0.68767746,  0.58660287,  0.56265356,\n",
       "         0.42156863,  0.98039216,  0.17460317,  0.90301003,  0.        ,\n",
       "         0.54255319]),\n",
       " array([ 0.        ,  0.87550201,  0.20253165,  0.        ,  0.80606007,\n",
       "         0.68374558,  0.74519427,  0.73371706,  0.65212766,  0.66618182,\n",
       "         0.56455142,  0.98765432,  0.28156997,  0.83796145,  0.        ,\n",
       "         0.64556962]),\n",
       " array([  58,  495,  142,   13, 5050, 1801, 1215, 1761, 1045,  814,  306,\n",
       "         408,  945, 5681,   94,   94]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.80952381,  0.        ,  0.        ,  0.63771712,\n",
       "         0.4       ,  0.36231884,  0.73262032,  0.49494949,  0.65079365,\n",
       "         0.85      ,  0.92592593,  0.34782609,  0.70227273,  0.        ,\n",
       "         0.4       ]),\n",
       " array([ 0.        ,  0.82258065,  0.        ,  0.        ,  0.81329114,\n",
       "         0.41777778,  0.32894737,  0.62272727,  0.2816092 ,  0.40196078,\n",
       "         0.43589744,  0.98039216,  0.06722689,  0.86919831,  0.        ,\n",
       "         0.16666667]),\n",
       " array([ 0.        ,  0.816     ,  0.        ,  0.        ,  0.71488178,\n",
       "         0.40869565,  0.34482759,  0.67321867,  0.35897436,  0.4969697 ,\n",
       "         0.57627119,  0.95238095,  0.11267606,  0.77686989,  0.        ,\n",
       "         0.23529412]),\n",
       " array([  8,  62,  18,   6, 632, 225, 152, 220, 174, 102,  39,  51, 119,\n",
       "        711,  42,  12]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = {\n",
    "     'SVCrbf': SVC(kernel='rbf', C=1.6, gamma = 0.003),\n",
    "}\n",
    "\n",
    "# feature_sets = features.columns.levels[0];\n",
    "feature_sets = {\n",
    "     'all': ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "           'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "           'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "}\n",
    "\n",
    "\n",
    "# test_classifiers_features:\n",
    "# scores.test, scores.train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "scores_test, scores_train, times, Precision_recall_train, Precision_recall_test, confusion_train, confusion_test = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores_test))\n",
    "ipd.display(format_scores(scores_train))\n",
    "#ipd.display(format_scores(score))\n",
    "ipd.display(times.style.format('{:.4f}'))\n",
    "ipd.display(Precision_recall_train)\n",
    "ipd.display(Precision_recall_test)\n",
    "\n",
    "# Score for LR model with all features: 61.10% (dim: 518)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(confusion_train)\n",
    "ipd.display(confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## normalize the matrices\n",
    "\n",
    "df_test = pd.DataFrame(confusion_test, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "df_test_norm = (df_test-df_test.mean())/df_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.DataFrame(confusion_train, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "# df_train_norm = (df_train-df_train.mean())/df_train.std()*100\n",
    "df_train_norm = df_train/(df_train.sum()+0.000001)*100\n",
    "\n",
    "# df_cm = pd.DataFrame(confusion_train, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "#                   columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_train, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_train_norm, annot=True, cmap=\"Blues\", fmt='.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(confusion_test, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "# df_test_norm = (df_test-df_test.mean())/df_test.std()\n",
    "df_test_norm = df_test/(df_test.sum()+0.00001)*100\n",
    "\n",
    "# df_cm_test = pd.DataFrame(df_test, index = [i for i in \"ABCDEFGHIJKLMNOP\"],\n",
    "#                   columns = [i for i in \"ABCDEFGHIJKLMNOP\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_test, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_test_norm, annot=True, cmap=\"Blues\", fmt='.1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=16)\n",
    "plt.title('Training data distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test, bins=16)\n",
    "plt.title('Test data distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features.loc[:,feature_sets]\n",
    "#name, fset = tqdm_notebook(feature_sets.items(), desc='features')\n",
    "features.loc[:, ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "             'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "             'spectral_rolloff', 'tonnetz', 'zcr']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 SVM with regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers: a dict with a key(name) and a classifier function;\n",
    "# feature_sets: a dict with a key(name) and a set of features: specified features subset extracted from 'features' used in model;\n",
    "# Function usage: compute score for each classifier with each feature_sets as features;\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    \n",
    "    columns = list(classifiers.keys()) # insert a column 'dim';\n",
    "    \n",
    "    # an accuracy dataframe and time dataframe;\n",
    "    # columns: classifiers.keys;  index: feature_sets.keys();\n",
    "    scores_test = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    scores_train = pd.DataFrame(columns = columns, index = feature_sets.keys())\n",
    "    times = pd.DataFrame(columns = classifiers.keys(), index = feature_sets.keys())\n",
    "    \n",
    "    precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1,\n",
    "                                    average=None, warn_for=(‘precision’, ’recall’, ’f-score’), \n",
    "                                    sample_weight=None)\n",
    "    \n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        \n",
    "        # pre-process: columns = fset, that is, it only uses only one feature per iteration.\n",
    "        # multi_label=False: use 'genre_top'(16) as labels y;\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores_test.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        scores_train.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score_test = clf.score(X_test, y_test) # accuracy for function clf.\n",
    "            score_train = clf.score(X_train, y_train) # accuracy for function clf.\n",
    "            scores_test.loc[fset_name, clf_name] = score_test\n",
    "            scores_train.loc[fset_name, clf_name] = score_train\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "    return scores_test, scores_train, times\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    \n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    \n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.estimators import svm\n",
    "classifiers = {\n",
    "\n",
    "}\n",
    "\n",
    "# feature_sets = features.columns.levels[0];\n",
    "feature_sets = {\n",
    "     'all': ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
    "           'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
    "           'spectral_rolloff', 'tonnetz', 'zcr']\n",
    "}\n",
    "\n",
    "\n",
    "# test_classifiers_features:\n",
    "# scores.test, scores.train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "scores_test, scores_train, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores_test))\n",
    "ipd.display(format_scores(scores_train))\n",
    "#ipd.display(format_scores(score))\n",
    "ipd.display(times.style.format('{:.4f}'))\n",
    "\n",
    "# Score for LR model with all features: 61.10% (dim: 518)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((*loader.shape, 1),  input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(3, 13, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(15, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(65, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(1e-3)#lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=16), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=16), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=16), test.size, **params)\n",
    "#Y = model.predict_generator(loader, test.size, pickle_safe=True, nb_worker=NB_WORKER, max_q_size=5)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MfccLoader(utils.Loader):\n",
    "    raw_loader = utils.FfmpegLoader(sampling_rate=22050)\n",
    "    #shape = (13, 190)  # For segmented tracks.\n",
    "    shape = (13, 2582)\n",
    "    def load(self, filename):\n",
    "        import librosa\n",
    "        x = self.raw_loader.load(filename)\n",
    "        # Each MFCC frame spans 23ms on the audio signal with 50% overlap with the adjacent frames.\n",
    "        mfcc = librosa.feature.mfcc(x, sr=22050, n_mfcc=13, n_fft=512, hop_length=256)\n",
    "        return mfcc\n",
    "\n",
    "loader = MfccLoader()\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "loader.load(utils.get_audio_path(AUDIO_DIR, 2))[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
